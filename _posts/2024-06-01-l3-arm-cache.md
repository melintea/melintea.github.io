---
layout: post
title: ARM: why not to construct a shared L3 cache 
---

Here is how 4-cores CPUs for Intel and ARM behave when the cache is churned hard. 
Both Intel and ARM caches have 64 bytes lines and 3 levels:

![_config.yml]({{ site.baseurl }}/images/rwlock-timing-intel1.png)
![_config.yml]({{ site.baseurl }}/images/rwlock-timing-arm1.png)

The ARM is kind of struggling, to the point that a piece of software optimized for Intel
has to be changed significantly:
- a Intel-optimal locking mechanism is not optiaml anymore on ARM.
- structures have to be realigned.
- maybe algorithms running on these structures may have to be changed as well.

Luckily, the stdlib reports (correctly) a huge offset is needed on this ARM to avoid false sharing,
so at least you have a hint:


    Offset                                         Intel   ARM
    ---------------------------------------------  ------  ------
    std::hardware_destructive_interference_size    64      256
    std::hardware_constructive_interference_size   64      64


Per cppreference[^2], above values are for L1 (256 for that level?):

"These constants provide a portable way to access the L1 data cache line size"

I believe the reason of this poor performance is more likely the L3 cache, optional for ARMs[^2]:

"All the cores in the cluster share the L3 cache". 


[^1]: [https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size]
[^2]: [https://developer.arm.com/documentation/100453/0401/L3-cache/About-the-L3-cache]
